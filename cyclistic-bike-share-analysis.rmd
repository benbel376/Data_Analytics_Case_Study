---
title: "cyclistic_bike_share_analysis"
author: "Biniyam Belayneh"
date: '2022-04-05'
output:
  html_document:
    number_sections: true
    toc: true
---

# Case Study: How Does a Bike-Share Navigate Speedy Success? 

#### Assumption: I am a data analyst at a fictional company called Cyclistic Bike Share

## Collecting Basic Information

### Objective
Design marketing strategies aimed at converting casual riders into annual members

### Stakeholders Interest

**Executive Team**

  * Having a new marketing strategy that can increase the number of profitable customers.
  
**Director of Marketing, Lily Moreno**

  * Analyzing the Cyclistic historical bike trip data to identify trends.
  * Finding marketing strategy that can convert casual riders to annual members

### Business task
How do annual members and casual riders use Cyclistic bikes differently?


## Checking Integrity and Preparing Datasets 

## data preparation

### Relevant Metrics
these metrics can be used to answer the business task by determining the difference (if any exists)
between the two types of users

* Duration of rides
* The purpose of rides
* Distance between destination and source stations
* time and date of ride


### loading important libraries
```{r libraries, message=FALSE, warning=FALSE}
library(skimr) # for quick comprehensive summary
library(tidyverse) # for data import and wrangling
library(geosphere) # to calculate distance with longtuide and latitude
library(sf) # to draw geographical charts.
library(lemon) # to draw good looking tables

knit_print.data.frame <- lemon_print
```
### loading important files
```{r source files, message=FALSE, warning=FALSE}

df_2022_02 <- read.csv("../input/divvy-tripdata-20222021/202202-divvy-tripdata/202202-divvy-tripdata.csv")
df_2022_01 <- read.csv("../input/divvy-tripdata-20222021/202201-divvy-tripdata/202201-divvy-tripdata.csv")
df_2021_12 <- read.csv("../input/divvy-tripdata-20222021/202112-divvy-tripdata/202112-divvy-tripdata.csv")
df_2021_11 <- read.csv("../input/divvy-tripdata-20222021/202111-divvy-tripdata/202111-divvy-tripdata.csv")
df_2021_10 <- read.csv("../input/divvy-tripdata-20222021/202110-divvy-tripdata/202110-divvy-tripdata.csv")
df_2021_09 <- read.csv("../input/divvy-tripdata-20222021/202109-divvy-tripdata/202109-divvy-tripdata.csv")
df_2021_08 <- read.csv("../input/divvy-tripdata-20222021/202108-divvy-tripdata/202108-divvy-tripdata.csv")
df_2021_07 <- read.csv("../input/divvy-tripdata-20222021/202107-divvy-tripdata/202107-divvy-tripdata.csv")
df_2021_06 <- read.csv("../input/divvy-tripdata-20222021/202106-divvy-tripdata/202106-divvy-tripdata.csv")
df_2021_05 <- read.csv("../input/divvy-tripdata-20222021/202105-divvy-tripdata/202105-divvy-tripdata.csv")
df_2021_04 <- read.csv("../input/divvy-tripdata-20222021/202104-divvy-tripdata/202104-divvy-tripdata.csv")
df_2021_03 <- read.csv("../input/divvy-tripdata-20222021/202103-divvy-tripdata/202103-divvy-tripdata.csv")
                                                     
```  
```{r checking column-names}
colnames(df_2022_02)
colnames(df_2022_01)
colnames(df_2021_12)
colnames(df_2021_11)
#...
```
column names across all the datasets are consistent so they can be combined
into one

```{r combining data frames, message=FALSE, warning=FALSE}
df_total <- bind_rows(df_2021_03, df_2021_04, df_2021_05, df_2021_06, df_2021_07, df_2021_08, df_2021_09, df_2021_10, df_2021_11, df_2021_12, df_2022_01, df_2022_02)

```

to make the data easier to work with lets take a random sample of size 500,000.
This enables us to run the file faster without severly compromizing accuracy of results.
                                                       
                                                       
```{r taking a sample}
df_total <- sample_n(df_total, 500000)
```

## Integrity Check

* The data is original becasue it is acquired directly from the primary data source
* It is cited because the company that collected the data is known [Original data source](https://divvy-tripdata.s3.amazonaws.com/index.html)
* It is current because the data is from the past 12 months (Feb 2022 - Mar 2021). 
* It is more or less comprehensive because it contains most of the variables needed to calculate the relevant metrics defined above. 
* It is reliable because the data is accurate, I dont see any bias in the collection of the data that favors particular groups over others; this is apparent from the fact that the company collects data on the basis of trips.  
* **In general, the dataset has integrity**

Now, lets further explore the contents of the datasets.


taking a first look at the data and summarizing it.

```{r}
dim(df_total)
```                                                                                   
```{r first inspection, message=FALSE, warning=FALSE, render=lemon_print}

head(df_total)
skim_without_charts(df_total)

```

### Observations

* there are a few missing values in station names, ids, and, longtude and latitude.
* there are redundant or irrelevant columns like station ids
* values in all columns have consistent length which suggests good formatting
* datatypes for all columns needs no modification
* the column names can be a little more clear
* there are no values that dont make sense.

lets further check the consistency of the values in some columns 
                                                                                     
### checking the datetime columns pattern consistency

creating a data frame for tests.

```{r test data frame, warning=FALSE}
df_total_test <- df_total %>% select(c(ride_id, started_at, ended_at))
```


**checking pattern consistency**

this allows us to determine if all the datetime values are of the same pattern or format (####-##-## ##:##:##)
    .
```{r pattern check, message=FALSE, warning=FALSE}
df_total_test$patternTestStart <- as.numeric(grepl("/^(202[1-2]{1})-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|[3[01]) (0[0-9]|1[0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])$/u", df_total_test$started_at))
df_total_test$patternTestEnd <- as.numeric(grepl("/^(202[1-2]{1})-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|[3[01]) (0[0-9]|1[0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])$/u", df_total_test$ended_at))

```


**checking range of datetime values**

checking if the datetime objects fall in the right date range. range of date should be between 2021-03-01 00:00:00 to 2022-02-28 23:59:59


```{r range check, message=FALSE, warning=FALSE}
df_total_test$start_date <- as.POSIXct(df_total_test$started_at) # converting to datetime object
df_total_test$end_date <- as.POSIXct(df_total_test$ended_at) # converting to datetime object

lower_lim = as.POSIXct("2021-03-01 00:00:00")
higher_lim = as.POSIXct("2022-02-28 23:59:59")

df_total_test <- df_total_test %>% mutate(match_start = ifelse(between(start_date, lower_lim, higher_lim), 1, 0), match_end = ifelse(between(start_date, lower_lim, higher_lim), 1, 0))

check <- df_total_test %>% filter(match_start == 0 | match_end == 0 | patternTestStart == 1 | patternTestEnd == 1)

# removing temporary data frame, df_total_test, that is created for the purpose of a test
rm(df_total_test)

```
**no values are outside the range or pattern**

# Cleaning the data

## removing irrelevant columns

```{r removing columns, message=FALSE, warning=FALSE}
df_total <- df_total %>% select(-c(start_station_id, end_station_id))

```

## giving each column a consistent and clear name

```{r column renaming, message=FALSE, warning=FALSE}
df_total <- rename(df_total, 
                   trip_id = ride_id,
                   bike_type = rideable_type,
                   start_time  = started_at,
                   end_time = ended_at,
                   source_name = start_station_name,
                   destination_name = end_station_name,
                   user_type = member_casual)

```

## removing duplicates if any

```{r duplicate removal}
df_total <- distinct(df_total) # complete duplicates

df_total <- distinct(df_total, trip_id, .keep_all = TRUE) # id duplicates

nrow(df_total) #no duplicates were found becuase number of rows didn't change

```


## removing rows with missing and empty values
missing and empty values do exist so...

```{r removing missing, message=FALSE, warning=FALSE}
df_total <- df_total %>% na_if("")

df_total_complete <- df_total %>% na.omit()

nrow(df_total_complete)

```


## final check before analysis
```{r final cleaning check, message=FALSE, warning=FALSE, render=lemon_print}
head(df_total_complete)
skim_without_charts(df_total_complete) 
```

data types, ranges, lengths and completeness looks good. now lets move on to 
data analysis.

                                                       
# Data Analysis

## Organize and Create New Variables

### create ride distance variable out of longtidue and latitudes (units in meters)

```{r Analyze - ride distance, message=FALSE, warning=FALSE}
df_total_complete$ride_distance <- round(apply(df_total_complete, 1, function(x)distm(c(x[8], x[7]), c(x[10], x[9]), fun = distGeo)), digits = 2)
```


### Create ride duration variable out of longtidue and latitude (units in minutes)

```{r Analyze - ride duration, message=FALSE, warning=FALSE}
df_total_complete$ride_duration <- round(as.numeric(difftime(df_total_complete$end_time, df_total_complete$start_time), units = "mins"), digits = 2)

# lets delete some values that don't make sense
df_total_complete <- df_total_complete %>% filter(ride_duration > 1)
```


### splitting the trip date and time to simplify aggregation over time periods

```{r Analyze - split date, message=FALSE, warning=FALSE}
df_total_complete$month <- format(as.Date(df_total_complete$start_time), "%m")
df_total_complete$day <- format(as.Date(df_total_complete$start_time), "%d")
df_total_complete$week_day <- format(as.Date(df_total_complete$start_time), "%A")
df_total_complete$day_hour <- format(as.POSIXlt(df_total_complete$start_time), "%H")

df_total_complete$week_day <- ordered(df_total_complete$week_day, levels=c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))
df_total_complete$month <- month.abb[as.numeric(df_total_complete$month)]
df_total_complete$month <- ordered(df_total_complete$month, levels=c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct","Nov", "Dec"))

```

## Descriptive Analysis

### summarizing ride distance and duration (mean, median, max, quartile, min)

```{r Analyze - summary, echo=TRUE, message=FALSE, warning=FALSE, render = lemon_print}
df_c <- cbind(df_total_complete)
summary(df_c$ride_distance)
summary(df_c$ride_duration)
table(df_c$user_type)


```

**Observation**
                                               
* a lot of rides are round trips. these trips have 0 ride_distance. this means the users returned the bikes to the same station they took them out from.
* the distance between source and destination stations is below 2.1KM for about 75% of the rides
* regarding duration of rides, 75% of the trips are below 22 minutes of ride.
* number of member riders are greater than casual riders

**lets compare casual riders and member riders accross different aggregated variables**


### round trips and user types

```{r round_trip, render = lemon_print}
df_c %>% filter(ride_distance == 0) %>% group_by(user_type) %>% summarize(cont = n())

```

casual users are more likely to return the bikes to the same station they took them out from.

### the top three source station and destination station names in each user categories

```{r Analyze - source names, message=FALSE, warning=FALSE, render=lemon_print}
# source names
src_cat <- df_c %>% group_by(user_type, source_name) %>% summarize(counted = n()) %>%arrange(user_type, desc(counted)) %>% slice (1:3)

# destination names
dest_cat <- df_c %>% group_by(user_type, destination_name) %>% summarize(counted = n()) %>% arrange(user_type, desc(counted)) %>% slice (1:3)

head(src_cat)
head(dest_cat)
```

the top three station names for casual riders is different from member riders

### ride duration and distance by ride time and user types

```{r Analyze - aggregation by time, message=FALSE, warning=FALSE}

aggregate_table_1 <- df_c %>% group_by(user_type, week_day) %>% 
  summarize(rides = n(),
            mean_duration = mean(ride_duration),
            median_duration = median(ride_duration),
            mean_distance = mean(ride_distance),
            median_distance = median(ride_distance))

aggregate_table_2 <- df_c %>% group_by(user_type, month) %>%
  summarize(rides = n(),
            mean_duration = mean(ride_duration),
            mean_distance = mean(ride_distance),
            median_duration = median(ride_duration),
            median_distance = median(ride_distance))

aggregate_table_3 <- df_c %>% group_by(day_hour, user_type) %>%
  summarize(rides = n(),
            mean_duration = mean(ride_duration),
            mean_distance = mean(ride_distance),
            median_duration = median(ride_duration),
            median_distance = median(ride_distance))


```
a few selected important insights acquired from the above aggregations will be shown below

# Visualization.


### Geographic distribution of source stations per user type 

```{r Visualize - source geo, message=FALSE, warning=FALSE}

my_sf <- st_as_sf(df_c, coords = c('start_lng', 'start_lat'), crs = 4326 )
options(repr.plot.width = 5, repr.plot.height =2)
ggplot(my_sf) + geom_sf(aes(color = user_type)) + facet_wrap(~user_type) +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```
There is generally no geographic difference between casual and member riders except that member riders are little 
more concentrated than casual riders who seem to be slightly more scattered. member riders show a little more regularity

### number of rides by day of the week and user type

```{r Visualize_number by day, message=FALSE, warning=FALSE}
aggregate_table_1 %>% ggplot(aes(x=user_type, y = rides, fill = week_day)) + geom_col(position = "dodge")
```

Casual riders can be seen as more of a weekend riders. the number of rides for member rides is highest in the middle of 
the week while the number of rides is significantly higher in the weekends for casual riders. there seems to be a smaller
variation between number of rides for member riders than casual riders. and in general the number of rides by member riders
is higher than those of casual riders except on the weekends.

### duration of rides by day of the week and user type

```{r Visualize - duration by day, message=FALSE, warning=FALSE}

aggregate_table_1 %>% ggplot(aes(x = week_day, y = median_duration, fill = user_type)) + geom_col(position = "dodge")

```

                                               
the duration of rides stays more or less consistent for member rides, which suggests that the member riders probably have a routine trips like 
like commuting to and from work.  

### number of rides by month and user type

```{r Visualize - by month, message=FALSE, warning=FALSE}
aggregate_table_2 %>% ggplot(aes(x = month, y = rides, fill = user_type)) + geom_col(position = "dodge")
```


significant seasonality is observed in the number of rides for both member and casual riders. summer time (Jun - Aug) is when the most number of rides
are observed while winter times (Feb and Jan) are the least prefered times of the year to ride bikes. This might suggest temparature is one factor
that controls the number of rides. the number of rides by casual riders spikes higher than those of member riders on the warm season and drops
significanlty below those of member riders on the cold season, which again suggests member riders having a fixed reason for using bikes.

### number of rides by time of the day and user type

```{r Visualize - by time, message=FALSE, warning=FALSE}

aggregate_table_3 %>% ggplot(aes(x = day_hour, y = rides, fill = user_type)) + geom_col(position = "dodge")

```


**General Observations**

* During weekends, the ride duration and distance spike for casual riders. casual riders are inconsistent riders 
* Member riders have a lot more consistency to their ride durations, which might be due to a fixed purpose of usage like commuting from home to work and vise versa.
* Seasons affect the number of rides in both user type categories considerablly. however seasonality seems to affect the number of casual riders more strongly
                                               
# Recomendations and Limitations.
In order to convert casual riders into the more consistent member riders, the company can create a special membership subscriptions
with free rides on the weekends of the winter season.
one limitation of this analysis is lacking information on the usage purpose of the riders.

# Exporting
```{r saving analysis files}
write.csv(df_c, "./cleaned_data.csv", row.names = FALSE)
write.csv(aggregate_table_1, "./aggregate_usertype_weekday.csv", row.names = FALSE)
write.csv(aggregate_table_2, "./aggregate_usertype_month.csv", row.names = FALSE)                                               
```